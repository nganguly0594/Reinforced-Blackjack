{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Setting Up the RL Agent Training Environment\n",
    "\n",
    "In this section, I go through a few different potential playing strategies for blackjack and offer an analysis on each of them. Namely, the 3 strategies I will test are a Discrete Standing Strategy, a Stochastic Standing Strategy, and probably the most well-known and mathematically proven strategy known as of today, the Basic Strategy. (Another more complex strategy based off of Basic Strategy involves a concept called \"card counting\" which I will not be showing.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take the stuff from gym.ipynb on how i set up this env and also no splitting in this environment, maybe add one for splitting later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class BlackjackEnv in module environment:\n",
      "\n",
      "class BlackjackEnv(gymnasium.core.Env)\n",
      " |  BlackjackEnv(higher_payout=False)\n",
      " |\n",
      " |  # Environment for only hitting, standing, and doubling down\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      BlackjackEnv\n",
      " |      gymnasium.core.Env\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, higher_payout=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  reset(self)\n",
      " |      Resets the environment to an initial internal state, returning an initial observation and info.\n",
      " |\n",
      " |      This method generates a new starting state often with some randomness to ensure that the agent explores the\n",
      " |      state space and learns a generalised policy about the environment. This randomness can be controlled\n",
      " |      with the ``seed`` parameter otherwise if the environment already has a random number generator and\n",
      " |      :meth:`reset` is called with ``seed=None``, the RNG is not reset.\n",
      " |\n",
      " |      Therefore, :meth:`reset` should (in the typical use case) be called with a seed right after initialization and then never again.\n",
      " |\n",
      " |      For Custom environments, the first line of :meth:`reset` should be ``super().reset(seed=seed)`` which implements\n",
      " |      the seeding correctly.\n",
      " |\n",
      " |      .. versionchanged:: v0.25\n",
      " |\n",
      " |          The ``return_info`` parameter was removed and now info is expected to be returned.\n",
      " |\n",
      " |      Args:\n",
      " |          seed (optional int): The seed that is used to initialize the environment's PRNG (`np_random`).\n",
      " |              If the environment does not already have a PRNG and ``seed=None`` (the default option) is passed,\n",
      " |              a seed will be chosen from some source of entropy (e.g. timestamp or /dev/urandom).\n",
      " |              However, if the environment already has a PRNG and ``seed=None`` is passed, the PRNG will *not* be reset.\n",
      " |              If you pass an integer, the PRNG will be reset even if it already exists.\n",
      " |              Usually, you want to pass an integer *right after the environment has been initialized and then never again*.\n",
      " |              Please refer to the minimal example above to see this paradigm in action.\n",
      " |          options (optional dict): Additional information to specify how the environment is reset (optional,\n",
      " |              depending on the specific environment)\n",
      " |\n",
      " |      Returns:\n",
      " |          observation (ObsType): Observation of the initial state. This will be an element of :attr:`observation_space`\n",
      " |              (typically a numpy array) and is analogous to the observation returned by :meth:`step`.\n",
      " |          info (dictionary):  This dictionary contains auxiliary information complementing ``observation``. It should be analogous to\n",
      " |              the ``info`` returned by :meth:`step`.\n",
      " |\n",
      " |  step(self, action)\n",
      " |      Run one timestep of the environment's dynamics using the agent actions.\n",
      " |\n",
      " |      When the end of an episode is reached (``terminated or truncated``), it is necessary to call :meth:`reset` to\n",
      " |      reset this environment's state for the next episode.\n",
      " |\n",
      " |      .. versionchanged:: 0.26\n",
      " |\n",
      " |          The Step API was changed removing ``done`` in favor of ``terminated`` and ``truncated`` to make it clearer\n",
      " |          to users when the environment had terminated or truncated which is critical for reinforcement learning\n",
      " |          bootstrapping algorithms.\n",
      " |\n",
      " |      Args:\n",
      " |          action (ActType): an action provided by the agent to update the environment state.\n",
      " |\n",
      " |      Returns:\n",
      " |          observation (ObsType): An element of the environment's :attr:`observation_space` as the next observation due to the agent actions.\n",
      " |              An example is a numpy array containing the positions and velocities of the pole in CartPole.\n",
      " |          reward (float): The reward as a result of taking the action.\n",
      " |          terminated (bool): Whether the agent reaches the terminal state (as defined under the MDP of the task)\n",
      " |              which can be positive or negative. An example is reaching the goal state or moving into the lava from\n",
      " |              the Sutton and Barton, Gridworld. If true, the user needs to call :meth:`reset`.\n",
      " |          truncated (bool): Whether the truncation condition outside the scope of the MDP is satisfied.\n",
      " |              Typically, this is a timelimit, but could also be used to indicate an agent physically going out of bounds.\n",
      " |              Can be used to end the episode prematurely before a terminal state is reached.\n",
      " |              If true, the user needs to call :meth:`reset`.\n",
      " |          info (dict): Contains auxiliary diagnostic information (helpful for debugging, learning, and logging).\n",
      " |              This might, for instance, contain: metrics that describe the agent's performance state, variables that are\n",
      " |              hidden from observations, or individual reward terms that are combined to produce the total reward.\n",
      " |              In OpenAI Gym <v26, it contains \"TimeLimit.truncated\" to distinguish truncation and termination,\n",
      " |              however this is deprecated in favour of returning terminated and truncated variables.\n",
      " |          done (bool): (Deprecated) A boolean value for if the episode has ended, in which case further :meth:`step` calls will\n",
      " |              return undefined results. This was removed in OpenAI Gym v26 in favor of terminated and truncated attributes.\n",
      " |              A done signal may be emitted for different reasons: Maybe the task underlying the environment was solved successfully,\n",
      " |              a certain timelimit was exceeded, or the physics simulation has entered an invalid state.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __annotations__ = {}\n",
      " |\n",
      " |  __parameters__ = ()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gymnasium.core.Env:\n",
      " |\n",
      " |  __enter__(self)\n",
      " |      Support with-statement for the environment.\n",
      " |\n",
      " |  __exit__(self, *args)\n",
      " |      Support with-statement for the environment and closes the environment.\n",
      " |\n",
      " |  __str__(self)\n",
      " |      Returns a string of the environment with :attr:`spec` id's if :attr:`spec.\n",
      " |\n",
      " |      Returns:\n",
      " |          A string identifying the environment\n",
      " |\n",
      " |  close(self)\n",
      " |      After the user has finished using the environment, close contains the code necessary to \"clean up\" the environment.\n",
      " |\n",
      " |      This is critical for closing rendering windows, database or HTTP connections.\n",
      " |\n",
      " |  render(self) -> Union[~RenderFrame, List[~RenderFrame], NoneType]\n",
      " |      Compute the render frames as specified by :attr:`render_mode` during the initialization of the environment.\n",
      " |\n",
      " |      The environment's :attr:`metadata` render modes (`env.metadata[\"render_modes\"]`) should contain the possible\n",
      " |      ways to implement the render modes. In addition, list versions for most render modes is achieved through\n",
      " |      `gymnasium.make` which automatically applies a wrapper to collect rendered frames.\n",
      " |\n",
      " |      Note:\n",
      " |          As the :attr:`render_mode` is known during ``__init__``, the objects used to render the environment state\n",
      " |          should be initialised in ``__init__``.\n",
      " |\n",
      " |      By convention, if the :attr:`render_mode` is:\n",
      " |\n",
      " |      - None (default): no render is computed.\n",
      " |      - \"human\": The environment is continuously rendered in the current display or terminal, usually for human consumption.\n",
      " |        This rendering should occur during :meth:`step` and :meth:`render` doesn't need to be called. Returns ``None``.\n",
      " |      - \"rgb_array\": Return a single frame representing the current state of the environment.\n",
      " |        A frame is a ``np.ndarray`` with shape ``(x, y, 3)`` representing RGB values for an x-by-y pixel image.\n",
      " |      - \"ansi\": Return a strings (``str``) or ``StringIO.StringIO`` containing a terminal-style text representation\n",
      " |        for each time step. The text can include newlines and ANSI escape sequences (e.g. for colors).\n",
      " |      - \"rgb_array_list\" and \"ansi_list\": List based version of render modes are possible (except Human) through the\n",
      " |        wrapper, :py:class:`gymnasium.wrappers.RenderCollection` that is automatically applied during ``gymnasium.make(..., render_mode=\"rgb_array_list\")``.\n",
      " |        The frames collected are popped after :meth:`render` is called or :meth:`reset`.\n",
      " |\n",
      " |      Note:\n",
      " |          Make sure that your class's :attr:`metadata` ``\"render_modes\"`` key includes the list of supported modes.\n",
      " |\n",
      " |      .. versionchanged:: 0.25.0\n",
      " |\n",
      " |          The render function was changed to no longer accept parameters, rather these parameters should be specified\n",
      " |          in the environment initialised, i.e., ``gymnasium.make(\"CartPole-v1\", render_mode=\"human\")``\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from gymnasium.core.Env:\n",
      " |\n",
      " |  unwrapped\n",
      " |      Returns the base non-wrapped environment (i.e., removes all wrappers).\n",
      " |\n",
      " |      Returns:\n",
      " |          Env: The base non-wrapped :class:`gymnasium.Env` instance\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gymnasium.core.Env:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  np_random\n",
      " |      Returns the environment's internal :attr:`_np_random` that if not set will initialise with a random seed.\n",
      " |\n",
      " |      Returns:\n",
      " |          Instances of `np.random.Generator`\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from gymnasium.core.Env:\n",
      " |\n",
      " |  __orig_bases__ = (typing.Generic[~ObsType, ~ActType],)\n",
      " |\n",
      " |  metadata = {'render_modes': []}\n",
      " |\n",
      " |  render_mode = None\n",
      " |\n",
      " |  reward_range = (-inf, inf)\n",
      " |\n",
      " |  spec = None\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |\n",
      " |  __class_getitem__(...)\n",
      " |      Parameterizes a generic class.\n",
      " |\n",
      " |      At least, parameterizing a generic class is the *main* thing this\n",
      " |      method does. For example, for some generic class `Foo`, this is called\n",
      " |      when we do `Foo[int]` - there, with `cls=Foo` and `params=int`.\n",
      " |\n",
      " |      However, note that this method is also called when defining generic\n",
      " |      classes in the first place with `class Foo[T]: ...`.\n",
      " |\n",
      " |  __init_subclass__(...)\n",
      " |      Function to initialize subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from environment import BlackjackEnv\n",
    "\n",
    "help(BlackjackEnv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blackjack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
